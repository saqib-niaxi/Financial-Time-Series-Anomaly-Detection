{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pKPwBSF1j8MG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Financial Time-Series Anomaly Detection"
      ],
      "metadata": {
        "id": "V58uNaSi5_uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import Libraries\n",
        "# Import all necessary libraries for data processing, modeling, and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "GjJjuaLEpuSd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Data Preprocessing\n",
        "# Load and preprocess the Yahoo Finance dataset\n",
        "def load_and_preprocess_data(file_path):\n",
        "    try:\n",
        "        print(f\"Loading data from {file_path}...\")\n",
        "        df = pd.read_excel(file_path, engine='openpyxl')\n",
        "        print(f\"Raw data shape: {df.shape}\")\n",
        "        print(f\"Raw data columns: {list(df.columns)}\")\n",
        "\n",
        "        if 'Date' not in df.columns:\n",
        "            raise ValueError(\"Expected 'Date' column not found in the dataset.\")\n",
        "\n",
        "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "        df = df.dropna(subset=['Date'])\n",
        "\n",
        "        expected_columns = ['Date', 'Open', 'High', 'Low', 'Close*', 'Volume']\n",
        "        available_columns = [col for col in expected_columns if col in df.columns]\n",
        "        if len(available_columns) < len(expected_columns):\n",
        "            missing = set(expected_columns) - set(available_columns)\n",
        "            print(f\"Warning: Missing columns {missing}. Proceeding with available columns.\")\n",
        "\n",
        "        df = df[available_columns].copy()\n",
        "\n",
        "        if 'Close*' in df.columns:\n",
        "            df.rename(columns={'Close*': 'Close'}, inplace=True)\n",
        "\n",
        "        df = df.dropna()\n",
        "        print(f\"Data shape after dropping NA: {df.shape}\")\n",
        "\n",
        "        lengths = {col: len(df[col]) for col in df.columns}\n",
        "        if len(set(lengths.values())) > 1:\n",
        "            raise ValueError(f\"Inconsistent column lengths: {lengths}\")\n",
        "\n",
        "        df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "        numeric_cols = [col for col in df.columns if col != 'Date']\n",
        "        for col in numeric_cols:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "        df = df.dropna()\n",
        "        print(f\"Final data shape: {df.shape}\")\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error in load_and_preprocess_data: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Execute data preprocessing\n",
        "file_path = '/content/yahoo_data.xlsx'  # Update if necessary\n",
        "df = load_and_preprocess_data(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxkmTbqStKz2",
        "outputId": "13df999c-d49f-43d4-b226-c83b283351e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/yahoo_data.xlsx...\n",
            "Raw data shape: (1258, 7)\n",
            "Raw data columns: ['Date', 'Open', 'High', 'Low', 'Close*', 'Adj Close**', 'Volume']\n",
            "Data shape after dropping NA: (1258, 6)\n",
            "Final data shape: (1258, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Calculate Financial Indicators\n",
        "# Compute SMA, EMA, RSI, and Bollinger Bands\n",
        "def calculate_indicators(df):\n",
        "    try:\n",
        "        df['SMA20'] = df['Close'].rolling(window=20).mean()\n",
        "        df['EMA20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
        "\n",
        "        delta = df['Close'].diff()\n",
        "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "        rs = gain / loss\n",
        "        df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "        df['BB_Middle'] = df['Close'].rolling(window=20).mean()\n",
        "        df['BB_Std'] = df['Close'].rolling(window=20).std()\n",
        "        df['BB_Upper'] = df['BB_Middle'] + 2 * df['BB_Std']\n",
        "        df['BB_Lower'] = df['BB_Middle'] - 2 * df['BB_Std']\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error in calculate_indicators: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Execute indicator calculation\n",
        "df = calculate_indicators(df)\n",
        "print(\"Financial indicators calculated. Columns:\", list(df.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDCKUw1J2nvO",
        "outputId": "ed63a608-cfce-484b-b6b3-6ced45279791"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Financial indicators calculated. Columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'SMA20', 'EMA20', 'RSI', 'BB_Middle', 'BB_Std', 'BB_Upper', 'BB_Lower']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect anomalies using Isolation Forest\n",
        "def detect_anomalies(df):\n",
        "    try:\n",
        "        features = ['Close', 'SMA20', 'EMA20', 'RSI', 'BB_Upper', 'BB_Lower', 'Volume']\n",
        "        X = df[features].dropna()\n",
        "\n",
        "        iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "        df.loc[X.index, 'Anomaly'] = iso_forest.fit_predict(X)\n",
        "\n",
        "        df['Anomaly'] = df['Anomaly'].apply(lambda x: 1 if x == -1 else 0)\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error in detect_anomalies: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Execute anomaly detection\n",
        "df = detect_anomalies(df)\n",
        "print(f\"Total anomalies detected: {df['Anomaly'].sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp6x1BIP2vaV",
        "outputId": "62b07d23-f4ed-4dcb-fb83-42332d43fb4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total anomalies detected: 62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for LSTM model\n",
        "def prepare_lstm_data(df, look_back=20):\n",
        "    try:\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        scaled_data = scaler.fit_transform(df[['Close']].values)\n",
        "\n",
        "        X, y = [], []\n",
        "        for i in range(look_back, len(scaled_data)):\n",
        "            X.append(scaled_data[i-look_back:i, 0])\n",
        "            y.append(scaled_data[i, 0])\n",
        "\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "        return X, y, scaler\n",
        "    except Exception as e:\n",
        "        print(f\"Error in prepare_lstm_data: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Execute data preparation\n",
        "X, y, scaler = prepare_lstm_data(df)\n",
        "print(f\"LSTM input shape: {X.shape}, Output shape: {y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlZ20EZI241C",
        "outputId": "5e2a417a-4fd6-49a9-e275-112735c74ef6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM input shape: (1238, 20, 1), Output shape: (1238,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and train the LSTM model\n",
        "def build_and_train_lstm(X, y):\n",
        "    try:\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "        model.add(LSTM(units=50))\n",
        "        model.add(Dense(units=1))\n",
        "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "        train_size = int(len(X) * 0.8)\n",
        "        X_train, X_test = X[:train_size], X[train_size:]\n",
        "        y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "        model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "        return model, X_test, y_test\n",
        "    except Exception as e:\n",
        "        print(f\"Error in build_and_train_lstm: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Execute model training\n",
        "model, X_test, y_test = build_and_train_lstm(X, y)\n",
        "print(f\"Test set size: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBzMmgEa2_me",
        "outputId": "17978715-f7d0-4cb2-b095-3d634d201e56"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 0.1118\n",
            "Epoch 2/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0046\n",
            "Epoch 3/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0022\n",
            "Epoch 4/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0016\n",
            "Epoch 5/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0018\n",
            "Epoch 6/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0016\n",
            "Epoch 7/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0018\n",
            "Epoch 8/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0022\n",
            "Epoch 9/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0018\n",
            "Epoch 10/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0017\n",
            "Test set size: 248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions and detect significant deviations\n",
        "def forecast_and_detect_deviations(df, model, X_test, y_test, scaler, look_back=20):\n",
        "    try:\n",
        "        predictions = model.predict(X_test, verbose=0)\n",
        "        predictions = scaler.inverse_transform(predictions)\n",
        "        actual = scaler.inverse_transform([y_test])[0]\n",
        "\n",
        "        deviations = np.abs(predictions.flatten() - actual) / actual\n",
        "        threshold = 0.05\n",
        "        significant_deviations = deviations > threshold\n",
        "\n",
        "        print(f\"Length of predictions: {len(predictions)}\")\n",
        "        print(f\"Length of actual: {len(actual)}\")\n",
        "        print(f\"Length of deviations: {len(deviations)}\")\n",
        "        print(f\"Length of significant_deviations: {len(significant_deviations)}\")\n",
        "        print(f\"Expected Date length: {len(df['Date'].iloc[-len(X_test):])}\")\n",
        "\n",
        "        forecast_df = pd.DataFrame({\n",
        "            'Date': df['Date'].iloc[-len(X_test):].values,\n",
        "            'Actual': actual,\n",
        "            'Predicted': predictions.flatten(),\n",
        "            'Deviation': deviations,\n",
        "            'Significant_Deviation': significant_deviations\n",
        "        })\n",
        "\n",
        "        return forecast_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error in forecast_and_detect_deviations: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Execute forecasting\n",
        "forecast_df = forecast_and_detect_deviations(df, model, X_test, y_test, scaler)\n",
        "print(f\"Significant deviations detected: {forecast_df['Significant_Deviation'].sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krnoPcVF3Elx",
        "outputId": "a0d5773c-ba55-4430-ab8f-0bdf4f518c30"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a591e492200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of predictions: 248\n",
            "Length of actual: 248\n",
            "Length of deviations: 248\n",
            "Length of significant_deviations: 248\n",
            "Expected Date length: 248\n",
            "Significant deviations detected: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and save visualizations\n",
        "def visualize_results(df, forecast_df, output_dir='plots'):\n",
        "    try:\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        sns.set(style='whitegrid')\n",
        "\n",
        "        plt.figure(figsize=(14, 7))\n",
        "        plt.plot(df['Date'], df['Close'], label='Close Price', color='blue')\n",
        "        plt.plot(df['Date'], df['SMA20'], label='SMA (20-day)', color='green')\n",
        "        plt.plot(df['Date'], df['EMA20'], label='EMA (20-day)', color='orange')\n",
        "        plt.plot(df['Date'], df['BB_Upper'], label='Bollinger Upper', color='red', linestyle='--')\n",
        "        plt.plot(df['Date'], df['BB_Lower'], label='Bollinger Lower', color='red', linestyle='--')\n",
        "        plt.title('Stock Price and Indicators')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Price')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'{output_dir}/price_indicators.png')\n",
        "        plt.close()\n",
        "\n",
        "        plt.figure(figsize=(14, 4))\n",
        "        plt.plot(df['Date'], df['RSI'], label='RSI', color='purple')\n",
        "        plt.axhline(70, color='red', linestyle='--', label='Overbought (70)')\n",
        "        plt.axhline(30, color='red', linestyle='--', label='Oversold (30)')\n",
        "        plt.title('Relative Strength Index (RSI)')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('RSI')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'{output_dir}/rsi.png')\n",
        "        plt.close()\n",
        "\n",
        "        plt.figure(figsize=(14, 7))\n",
        "        plt.plot(df['Date'], df['Close'], label='Close Price', color='blue', alpha=0.5)\n",
        "        anomalies = df[df['Anomaly'] == 1]\n",
        "        plt.scatter(anomalies['Date'], anomalies['Close'], color='red', label='Anomalies', marker='o')\n",
        "        plt.title('Detected Anomalies')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Price')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'{output_dir}/anomalies.png')\n",
        "        plt.close()\n",
        "\n",
        "        plt.figure(figsize=(14, 7))\n",
        "        plt.plot(forecast_df['Date'], forecast_df['Actual'], label='Actual Price', color='blue')\n",
        "        plt.plot(forecast_df['Date'], forecast_df['Predicted'], label='Predicted Price', color='orange')\n",
        "        deviations = forecast_df[forecast_df['Significant_Deviation']]\n",
        "        plt.scatter(deviations['Date'], deviations['Actual'], color='red', label='Significant Deviations', marker='o')\n",
        "        plt.title('LSTM Forecast and Significant Deviations')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Price')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'{output_dir}/forecast_deviations.png')\n",
        "        plt.close()\n",
        "\n",
        "        plt.figure(figsize=(14, 4))\n",
        "        plt.plot(df['Date'], df['Volume'], label='Volume', color='gray')\n",
        "        plt.title('Trading Volume')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Volume')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'{output_dir}/volume.png')\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"Visualizations saved in '{output_dir}' directory.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in visualize_results: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Execute visualization\n",
        "visualize_results(df, forecast_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0jqoJ7R3Npw",
        "outputId": "fc980920-2e8e-4f3a-b74a-8b2ce6b65e09"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualizations saved in 'plots' directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the final analysis report\n",
        "print(\"\\n=== Stock Anomaly Detection Report ===\")\n",
        "print(f\"Dataset: Dow Jones Industrial Average\")\n",
        "print(f\"Date Range: {df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')}\")\n",
        "print(f\"Total Anomalies Detected: {df['Anomaly'].sum()}\")\n",
        "print(f\"Significant Deviations in Forecast: {forecast_df['Significant_Deviation'].sum()}\")\n",
        "print(\"\\nKey Observations:\")\n",
        "print(\"- Anomalies are often associated with extreme RSI values or prices outside Bollinger Bands.\")\n",
        "print(\"- Significant deviations in LSTM forecasts may indicate unexpected market movements.\")\n",
        "print(\"- High volatility periods (e.g., March 2020) show clusters of anomalies.\")\n",
        "print(\"\\nVisualizations have been saved in the 'plots' directory:\")\n",
        "print(\"- price_indicators.png: Stock price with SMA, EMA, and Bollinger Bands\")\n",
        "print(\"- rsi.png: Relative Strength Index\")\n",
        "print(\"- anomalies.png: Detected anomalies\")\n",
        "print(\"- forecast_deviations.png: LSTM forecast with significant deviations\")\n",
        "print(\"- volume.png: Trading volume\")\n",
        "print(\"\\nConclusion:\")\n",
        "print(\"The analysis highlights periods of potential market manipulation or unusual activity, particularly during volatile periods. Traders should investigate these anomalies further and exercise caution.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg3a2l-n3ZDG",
        "outputId": "911e568e-6ed7-45f8-b6be-382e4c350778"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Stock Anomaly Detection Report ===\n",
            "Dataset: Dow Jones Industrial Average\n",
            "Date Range: 2018-05-01 to 2023-04-28\n",
            "Total Anomalies Detected: 62\n",
            "Significant Deviations in Forecast: 25\n",
            "\n",
            "Key Observations:\n",
            "- Anomalies are often associated with extreme RSI values or prices outside Bollinger Bands.\n",
            "- Significant deviations in LSTM forecasts may indicate unexpected market movements.\n",
            "- High volatility periods (e.g., March 2020) show clusters of anomalies.\n",
            "\n",
            "Visualizations have been saved in the 'plots' directory:\n",
            "- price_indicators.png: Stock price with SMA, EMA, and Bollinger Bands\n",
            "- rsi.png: Relative Strength Index\n",
            "- anomalies.png: Detected anomalies\n",
            "- forecast_deviations.png: LSTM forecast with significant deviations\n",
            "- volume.png: Trading volume\n",
            "\n",
            "Conclusion:\n",
            "The analysis highlights periods of potential market manipulation or unusual activity, particularly during volatile periods. Traders should investigate these anomalies further and exercise caution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zv1fRTJJ3ihP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}